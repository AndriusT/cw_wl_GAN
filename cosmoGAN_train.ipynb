{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Weak Lensing Maps / Cosmic Web Slices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the script for training the cosmoGAN algorithm. If you want to train the algorithm on your own dataset be sure to do the following:\n",
    "\n",
    "* Set the output size accordingly. The \"output_size\" variable should be equal to the input dataset image dimensions (e.g. 256x256 px).\n",
    "* Currently the algorithm only works for images of the same height and width dimensions (e.g. 512x512 px etc).\n",
    "* The training dataset should be a python list/array of the following shape (No. of images x height x width (NHWC). The get_data() function will reshape the input the array by adding an extra dimension corresponding to the color dimension of the training images.\n",
    "* cosmoGAN can also be trained on RGB images (multidimensional arrays). For more information see the notebook on preparing Illustris data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Importing the libraries: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/c/Users/tamos/Desktop/PhD/for_github/functions.py:91: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pprint\n",
    "import functions\n",
    "from functions import train_dcgan\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A function to load the training data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data = np.load(config.datafile, mmap_mode='r')\n",
    "\n",
    "    if config.data_format == 'NHWC':  ## This is the data format: Number of images x height x width x color dimension\n",
    "        data = np.expand_dims(data, axis=-1)\n",
    "    else: # 'NCHW'\n",
    "        data = np.expand_dims(data, axis=1)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training settings: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "flags.DEFINE_string(\"dataset\", \"cosmic_web\", \"The name of the dataset\")\n",
    "flags.DEFINE_string(\"datafile\", \"./data/cosmogan_maps_256_8k_1.npy\", \"Training dataset file location\")\n",
    "flags.DEFINE_integer(\"epoch\", 5000, \"Epochs to train before stopping\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.00009, \"The learning rate parameter\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam (default value: 0.5)\")\n",
    "flags.DEFINE_float(\"flip_labels\", 0.01, \"Probability of flipping labels (default value: 0.01)\")\n",
    "flags.DEFINE_integer(\"z_dim\", 64, \"Dimension of noise vector z\")\n",
    "flags.DEFINE_integer(\"nd_layers\", 4, \"Number of discriminator convolutional layers (default value: 4)\")\n",
    "flags.DEFINE_integer(\"ng_layers\", 4, \"Number of generator conv_T layers (default value: 4)\")\n",
    "flags.DEFINE_integer(\"gf_dim\", 64, \"Dimension of generator filters in last conv layer (default value: 64)\")\n",
    "flags.DEFINE_integer(\"df_dim\", 64, \"Dimension of discriminator filters in first conv layer (default value: 64)\")\n",
    "flags.DEFINE_integer(\"batch_size\", 64, \"The size of batch images (default value: 64)\")\n",
    "flags.DEFINE_integer(\"output_size\", 256, \"The size of the output images to produce (default value: 64)\")\n",
    "flags.DEFINE_integer(\"c_dim\", 1, \"Dimension of image color. 1 = greyscale image, 3 = RGB image\")\n",
    "flags.DEFINE_string(\"data_format\", \"NHWC\", \"data format (NHWC = No. x height x width x color dimension while NCHW = no. x color dimesion x height x width)\")\n",
    "flags.DEFINE_boolean(\"transpose_matmul_b\", False, \"Transpose matmul B matrix for performance [False]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"./checkpoints/checkpoint_name\", \"Directory name to save the checkpoints (default value: checkpoint)\")\n",
    "flags.DEFINE_string(\"experiment\", \"run_0\", \"Tensorboard run directory name (run_0)\")\n",
    "flags.DEFINE_boolean(\"save_every_step\", False, \"Save a checkpoint after every step (default value: False)\")\n",
    "flags.DEFINE_boolean(\"verbose\", True, \"print loss on every step (default value: False)\")\n",
    "config = flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.PrettyPrinter().pprint(config.__flags)\n",
    "train_dcgan(get_data(), config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
